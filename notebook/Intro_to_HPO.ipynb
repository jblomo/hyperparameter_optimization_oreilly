{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction to Hyperparameter Optimization\n\n## Discussion of HPO principles and collaboration on an interactive use case\n\n`The tutorial will be run by Jim Blomo (jim@sigopt.com)`\n\n\n`Original content created by Jeremy Bivaud (jeremy@sigopt.com) and Tobias Andreasen (tobias@sigopt.com)`\n\n___\n\n## Introduction\n\n*Experimentation is critical to developing models but can be a messy process. Modelers often spend significant time on tasks like tracking runs, creating visualizations, and troubleshooting hyperparameter optimization jobs, all of which could be supported or automated with software.*\n\n*Join expert Jim Blomo to learn best practices for tracking, training, and tuning models and using the information from these processes to make the best decisions around the model development process. Youâ€™ll focus specifically on hyperparameter optimization (HPO): selecting the best method, executing tuning jobs, and analyzing the results of these jobs to select the best model for production. Along the way, youâ€™ll see firsthand just how useful HPO is through an anomaly detection problem (based on a Kaggle financial dataset) that uses an XGBoost classification model. Youâ€™ll then use SigOpt to perform your own tuning jobs and cover open source alternatives and how to implement them* - [O'Reilly](https://www.oreilly.com/live-training/courses/introduction-to-hyperparameter-optimization/0636920470830/#instructors)\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Instructor: Jim Blomo\n\n*Jim Blomo is an executive engineering leader at SigOpt. Heâ€™s achieved strong business results in technology companies by creating a culture of performance, innovation, and teamwork. Previously, Jim led data-mining efforts as a director of engineering at Yelp, operations at the startup PBWorks, and search infrastructure at Amazonâ€™s A9 subsidiary. He enjoys speaking and travel; heâ€™s lectured on data mining and web architecture at UC Berkeley's School of Information and presented at conferences such as AWS re:Invent, Oâ€™Reilly OSCON, Wolfram Data Summit, and RecSys. He loves exploring the food and outdoors of the Bay Area with his family* - [Jim Blomo](https://www.linkedin.com/in/jimblomo/)\n\n<img src=\"https://sigopt.com/wp-content/uploads/2019/02/img-Jim.jpg\" alt=\"Black Box Overview\"  width=\"200\" align=\"center\"/> \n\n<img src=\"https://static.sigopt.com/b/ac75899cedb91b80acf515ed92fef03aa4ef690d/static/img/SigOpt_logo_horiz.svg\" alt=\"Black Box Overview\" width=\"300\"/>\n\n___"},{"metadata":{"id":"jmUeuv7a1n5E"},"cell_type":"markdown","source":"# Session Abstract\n\nThis sessionâ€™s primary objective is to teach attendees how to balance model training and hyperparameter tuning to develop high-performing models. Its secondary objective is to dive deeper into hyperparameter tuning, and, through the process, help attendees develop some intuition around the practical aspects of automated model optimization.\n\n> First, we will spend time discussing the best ways to track runs as you go through the modeling process. Second, we will discuss useful visualizations for analyzing model behavior, comparing architectures, and evaluating metrics. Finally, we will delve into methods for automated hyperparameter optimization with a focus on how tuning hyperparameters boosts model performance, provides model insights, and bolsters modeling workflows and team collaboration.\n\nWe will present an anomaly detection problem based on this [Kaggle financial dataset](https://www.kaggle.com/ntnu-testimon/paysim1) using a [XGBoost classification model](https://xgboost.readthedocs.io/en/latest/) to show rather than tell how HPO can be useful. After presenting the use case and the dataset, weâ€™ll dive into the optimization journey, presenting the model performance and workflow uplifts that a modeler can observe when following a structured optimization approach using SigOpt. The session will feature multiple interactive sections including code exercises and group discussions that will utilize Jupyter notebooks. Every attendee will get free access to [SigOpt](https://sigopt.com/) so they can perform their own tuning jobs as part of the tutorial. We will also cover open source alternatives to SigOpt and train attendees on how to integrate them if they need a replacement for SigOpt.\n\n\n## ðŸš¦ **TO DO [Recommended but optional] - Sign up for a free SigOpt account in order to follow along during the tutorial - [SIGN UP FOR SIGOPT](https://modeling.sigopt.com/oreilly-offer).**\n\n*- After signing up for the SigOpt account you will recieve an email with instructions on how to activate your personal SigOpt account.*\n\n___"},{"metadata":{"id":"zWQDFfjR1n5F"},"cell_type":"markdown","source":"# Session Agenda\n\nThis session is divided in three sections;\n\n* [__Data Import and preprocessing__](#Data-Import-and-Preprocessing)\n    * Modeling Environment\n    * Importing Libraries\n    * Importing the Dataset\n    * Defining our Feature and Label Sets\n    * Objective Metric Selection\n    * Splitting the dataset\n* [__Experiment Tracking__](#Experiment-Tracking)\n    * Experiment Tracking with SigOpt\n        * Training Runs\n        * Experiments\n    * Setting Up SigOpt\n    * Setting our baseline\n* [__Hyperparameter Optimization__](#Hyperparameter-Optimization)\n    * Define your Parameter Space\n    * Configure your Experiment\n    * Instrument your model and run your Experiment\n    * Multimetric Experimentation\n* [__Learn more at your own time__](#Learn-more-at-your-own-time)\n    * EfficientBERT\n    * Advanced features\n    * Documentation\n\nThere will be a 5 min break between the Experiment Tracking and Hyperparameter Optimization sections. Let's get started!\n\n___"},{"metadata":{},"cell_type":"markdown","source":"# Data Import and Preprocessing\n\n## Modeling Envirnment\n\nIn the interest of time we have already prepared the environment that we'll be using for this tutorial. All of the libraries listed belowe have been install using *pip install*'.\n\nðŸš¦ **TO DO - Run the following code cell to have a look at the environment that we will be using for the tutorial.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../requirements.txt', 'r') as txt:\n    print('Preinstalled libraries: \\n')\n    print(txt.read())","execution_count":1,"outputs":[{"output_type":"stream","text":"Preinstalled libraries: \n\nKeras==2.4.3\njupyter==1.0.0\npandas==1.1.2\nscikit-learn==0.23.2\ntensorflow==2.3.0\nxgboost==1.2.0\nhttps://sigopt-python-mpm.s3-us-west-1.amazonaws.com/sigopt-7.1.4-py2.py3-none-any.whl\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries\nAll of the above libraries have bee pre-installed and are ready to be imported.\n\nLinks and a short description of why each of these libraries are important for the tutorial can be found below.\n- **pandas** to load the data file as a Pandas dataframe, analyze and process the data directly within the notebook\n- **numpy** and **math** for computing scientific functions\n- **time** to measure inference and training time\n- **SigOpt** for experimentation and optimization\n- from **sklearn**, we'll import [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split our dataset into train and test subsets, [average_precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html), [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) to track our model performance\n- and finally, from **xgboost**, we'll import the [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier) class that we will use to build and parametrize our model\n\nWe also use a random_state variable across this notebook to guarantee that all our functions are deterministic, and results are repeatable.\n\nðŸš¦ **TO DO - Run the following code cell to import the required libraries and classes.**"},{"metadata":{"id":"QkcWiyaK1n5H","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport math\nimport time\nimport sigopt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, average_precision_score, f1_score \nfrom xgboost.sklearn import XGBClassifier\nrandom_state = 3","execution_count":2,"outputs":[]},{"metadata":{"id":"rt5qDTFa1n5L"},"cell_type":"markdown","source":"## Importing the Dataset\nThe dataset we are using is a synthetic dataset generated using the [PaySim](https://github.com/EdgarLopezPhD/PaySim) simulator. PaySim uses aggregated data from a private dataset to generate a synthetic dataset that resembles the normal operation of transactions and injects malicious behavior to later evaluate the performance of fraud detection methods. The dataset is publicly available under this kaggle [project](https://www.kaggle.com/ntnu-testimon/paysim1). For your convenience we performed the data preprocessing and feature engineering on the dataset. We also picked a 10% subset of this data so we can iterate fast and try enough sets of hyperparameters to showcase the optimization process and still fit this journey within a two hour interactive session.\n\nðŸš¦ **TO DO - Run the following code cell to import the data set and create the corresponding Pandas dataframe.**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"kHQ87NyY1n5L","outputId":"d91fd3f7-a6fe-4d40-b174-ac9be38f4cb4","trusted":true},"cell_type":"code","source":"df_path = '../data/Fraud_Detection_SigOpt_dataset.csv'\ndf = pd.read_csv(df_path)\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   step  type     amount  oldBalanceOrig  newBalanceOrig  oldBalanceDest  \\\n0     1     0     181.00           181.0             0.0             0.0   \n1     1     1     181.00           181.0             0.0         21182.0   \n2     1     1  229133.94         15325.0             0.0          5083.0   \n3     1     0  215310.30           705.0             0.0         22425.0   \n4     1     0  311685.89         10835.0             0.0          6267.0   \n\n   newBalanceDest  isFraud  errorBalanceOrig  errorBalanceDest  \n0            0.00        1              0.00             181.0  \n1            0.00        1              0.00           21363.0  \n2        51513.44        0         213808.94          182703.5  \n3            0.00        0         214605.30          237735.3  \n4      2719172.89        0         300850.89        -2401220.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>type</th>\n      <th>amount</th>\n      <th>oldBalanceOrig</th>\n      <th>newBalanceOrig</th>\n      <th>oldBalanceDest</th>\n      <th>newBalanceDest</th>\n      <th>isFraud</th>\n      <th>errorBalanceOrig</th>\n      <th>errorBalanceDest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>181.00</td>\n      <td>181.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>181.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>181.00</td>\n      <td>181.0</td>\n      <td>0.0</td>\n      <td>21182.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>21363.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>229133.94</td>\n      <td>15325.0</td>\n      <td>0.0</td>\n      <td>5083.0</td>\n      <td>51513.44</td>\n      <td>0</td>\n      <td>213808.94</td>\n      <td>182703.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>215310.30</td>\n      <td>705.0</td>\n      <td>0.0</td>\n      <td>22425.0</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>214605.30</td>\n      <td>237735.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>311685.89</td>\n      <td>10835.0</td>\n      <td>0.0</td>\n      <td>6267.0</td>\n      <td>2719172.89</td>\n      <td>0</td>\n      <td>300850.89</td>\n      <td>-2401220.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"id":"IafCRqoO1n5P"},"cell_type":"markdown","source":"## Defining our Feature and Label Sets\nðŸš¦ **TO DO - Run the following code cell to split our dataset into the feature set X and the label set Y.**"},{"metadata":{"id":"gGKkkLy81n5P","trusted":true},"cell_type":"code","source":"X = df\nY = df['isFraud']\ndel X['isFraud']","execution_count":4,"outputs":[]},{"metadata":{"id":"BIax6nK71n5T"},"cell_type":"markdown","source":"In most Anomaly Detection problems, the main obstacle for training a robust ML model is the highly imbalanced nature of the data.  The formula below returns a measure of the dataset skew, which is is the share of fraudulent transactions in our dataset which is a little more than .1%\n\nðŸš¦ **TO DO - Run the following code cell to find out the share of fraudulent activity in your dataset**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"LCc23O8J1n5U","outputId":"1e770585-bdc8-48ab-c118-d488e59dc187","trusted":true},"cell_type":"code","source":"print('Share of fraudulent activity: {}%'.format(100*(len(Y.loc[Y == 1]) / float(len(Y)))))","execution_count":5,"outputs":[{"output_type":"stream","text":"Share of fraudulent activity: 0.1378084498528364%\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Objective Metric Selection\n\nNow that we have established that the dataset is highly skewed towards one of our classes. It is important to pick  metrics that are able to account for this type of class imbalance. For this tutorial we will focus on some common  metrics used for imbalanced dataset:\n\n- **F1-score**, **precision** and **recall**: F1 is a wieghted average of precision and recell and tryes to account for one class having a larger representation than the other.\n- **Area under the precision-recall curve (AUPRC)** and **area under the receiver operating characteristic (AUROC)**: these two metrics do have similar characteristics, but oftentimes AUPRC does a better job than AUROC at weighing incorrect predictions that occur in the minority class. More info on this tradeoff in this [publication](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf).\n- **Confusion matrix**: the confusion matrix provides the counts of predictions compared to the actual label.\n\nAdditionally, computing business level metrics allows modelers to translate model behavior into impacts other stakeholders may care about. This step is critical in explaining how a model will likely behaive in production.\n\n- **max_missed_fraud( )**: The maximum transaction amount we missed flagging as fraud (false negative)\n- **max_missed_valid( )**: The maximum transaction amount we missed flagging as valid (false positive)\n\nðŸš¦ **TO DO - Run the following code cells to define these two objective metrics**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def max_missed_fraud(prediction, label, amount):\n    \"\"\"record the mean transaction amount from missing fraudulent transactions\"\"\"\n    fn_vec = (~prediction) & (label > 0)\n    fraud_loss_max = np.where(fn_vec, np.abs(amount), np.zeros_like(amount)).max()\n    return fraud_loss_max","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def max_missed_valid(prediction, label, amount):\n    \"\"\"record the mean transaction amount from flagging valid transactions\"\"\"\n    fp_vec = prediction & (label == 0)\n    valid_loss_max = np.where(fp_vec, np.abs(amount), np.zeros_like(amount)).max()\n    return valid_loss_max","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercise: Define a business metric\n\nDefine your own definition of a business metric you think a stakeholder would care about. Write the code below, which includes a simple test case.\n\nðŸš¦ **TO DO - Fill in the function below to compute a business metric. Run the cell to run a simple test.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def exercise_business_metric(prediction, label, amount):\n    \"\"\"TODO: Fill in your documentation\"\"\"\n    # TODO: Fill in your code here, and replace the raise statement with a return\n    raise NotImplementedError(\"TODO: Fill in code\")\n    \nprint(exercise_business_metric(np.array([1,1,0,0]), np.array([1,0,1,0]), np.array([10,20,30,40])))","execution_count":8,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"TODO: Fill in code","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-21ff4692c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TODO: Fill in code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise_business_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-21ff4692c27f>\u001b[0m in \u001b[0;36mexercise_business_metric\u001b[0;34m(prediction, label, amount)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"TODO: Fill in your documentation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# TODO: Fill in your code here, and replace the raise statement with a return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TODO: Fill in code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise_business_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: TODO: Fill in code"]}]},{"metadata":{},"cell_type":"markdown","source":"## Consistent Metric Logging\n\nHaving a consistent place to log all your metrics can ensure you have all the data you need on hand to make decisions or engage in a discussion.\n\nðŸš¦ **TO DO - Add your new function above to the metrics being logged with `sigopt.log_metric`.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_all_metrics(prediction, probabilities, testY, testX):\n    \"\"\"Log all relevant metrics using the `predictions` generated by the model, \n    the `probabilities` associated with those predictions, the `testY` actual \n    labels from the dataset, and `testX` the features.\"\"\"\n    F1score = f1_score(testY,prediction)\n    AUPRC = average_precision_score(testY, probabilities)\n    tn, fp, fn, tp = confusion_matrix(testY,prediction).ravel()\n\n    sigopt.log_metric('AUPRC', average_precision_score(testY, probabilities))\n    sigopt.log_metric('F1score', F1score)\n    sigopt.log_metric('False Positive', fp)\n    sigopt.log_metric('False Negative', fn)\n    sigopt.log_metric('True Positive', tp)\n    sigopt.log_metric('True Negative', tn)\n    sigopt.log_metric('Max $ Missed Fraudulent', max_missed_fraud(prediction, testY, testX['amount']))\n    sigopt.log_metric('Max $ Missed Valid', max_missed_valid(prediction, testY, testX['amount']))","execution_count":9,"outputs":[]},{"metadata":{"id":"cgKGI2SV1n5Y"},"cell_type":"markdown","source":"## Splitting the dataset\n\nIt is important, that we produce a model which is able to generalize to unseen data. In order to do so, we split our full dataset into a training set (80% of the data) and a testing set (20% of the data).\n\nðŸš¦ **TO DO - Run the following code cell create your training and test sets**"},{"metadata":{"id":"KDURk10k1n5Y","trusted":true},"cell_type":"code","source":"trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2, random_state = random_state)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is important to notice that SigOpt is not limited to using a train/test-split for guaranteeing generalization. It is perfectly resonable to use things like k-fold, simulation etc. Ultimately it comes down to, what you feel the most comfortable with. \n\n___"},{"metadata":{"id":"gEOBwhKB1n5e"},"cell_type":"markdown","source":"### [Training Runs](https://app.sigopt.com/docs/runs/overview)\nA SigOpt Run stores the training and evaluation of a model, so that modelers can see a history of their work. This is the fundamental building block of SigOpt. Runs record everything you might need to understand how a model was built, reconstitute the model in the future, or explain the process to a colleague.\n\nCommon attributes of a Run include:\n- the model type,\n- dataset identifier,\n- evaluation metrics,\n- hyperparameters,\n- logs, and\n- a code reference.\n\nFor a complete list of attributes see the [API Reference](https://app.sigopt.com/docs/runs/reference). Training runs can be recorded by integrating code snippets into Python that you run in a [notebook](https://app.sigopt.com/docs/runs/notebook) or via the [command line](https://app.sigopt.com/docs/runs/editor)."},{"metadata":{"id":"wUjYRYjb1n5j"},"cell_type":"markdown","source":"## Setting up SigOpt\n\nBefore starting to do modeling, we will need to configure the SigOpt library to connect to the SigOpt backend and come up with a name for our project.\n\nðŸš¦ **TO DO - 1) log into your SigOpt account and access your own personal [API token](https://app.sigopt.com/tokens/info), 2) run the following code cell and 3) follow the instruction in order to connect to the SigOpt backend**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from getpass import getpass\nAPI_TOKEN = getpass('Insert your API token: ')\nos.environ['SIGOPT_API_TOKEN'] = API_TOKEN","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Insert your API token: Â·Â·Â·Â·Â·Â·Â·Â·\n"}]},{"metadata":{},"cell_type":"markdown","source":"ðŸš¦ **TO DO - 1) run the following code cell and 2) follow the instructions to name your project**"},{"metadata":{"id":"joLpvdww1n5k","trusted":true},"cell_type":"code","source":"%load_ext sigopt\nPROJECT_NAME = input('Name your project: ')\nos.environ['SIGOPT_PROJECT'] = PROJECT_NAME","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"Name your project: oreilly\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nimport keras.backend as K\nimport tensorflow as tf","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a Keras callback to record checkpoints\nclass CheckpointCB(Callback):\n    def on_train_begin(self, logs=None):\n        pass\n\n    def on_epoch_end(self, epoch, logs=None):\n        if logs:\n            sigopt.log_checkpoint(logs)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# implement f1 metric and loss to handle imbalanced dataset\nimport tensorflow as tf\nimport keras.backend as K\n\ndef f1(y_true, y_pred):\n    y_true = K.cast(y_true, 'float')\n    \n    tp = K.sum(y_true*y_pred, axis=0)\n    tn = K.sum((1-y_true)*(1-y_pred), axis=0)\n    fp = K.sum((1-y_true)*y_pred, axis=0)\n    fn = K.sum(y_true*(1-y_pred), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef f1_loss(y_true, y_pred):\n    y_true = K.cast(y_true, 'float')\n    \n    tp = K.sum(y_true*y_pred, axis=0)\n    tn = K.sum((1-y_true)*(1-y_pred), axis=0)\n    fp = K.sum((1-y_true)*y_pred, axis=0)\n    fn = K.sum(y_true*(1-y_pred), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    loss = 1 - f1\n    mean_loss = K.mean(loss)\n    return tf.where(mean_loss < K.epsilon(), tf.zeros_like(mean_loss), tf.math.log(mean_loss))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#standardizing the input feature\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n\nsc = StandardScaler()\nscaled_trainX, scaled_testX = sc.fit_transform(trainX), sc.fit_transform(testX)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ['SIGOPT_API_TOKEN']","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"'GUOSDWFOXYMZYAGRRKFRROZVLEXIUREMASTTONZYMLHADRSW'"},"metadata":{}}]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"%%run Keras First Run\n\nsigopt.log_model('MLP (keras.models.Sequential)')\nsigopt.log_dataset('Scaled ' + dfpath)\n\n#model parametrization\nmodel_keras = Sequential()\nmodel_keras.add(Dense(\n    trainX.shape[1] * 2,\n    activation='relu',\n    kernel_initializer='random_normal',\n    bias_initializer='zeros',\n    input_dim=trainX.shape[1]\n))\nmodel_keras.add(Dense(\n    trainX.shape[1] * 2,\n    activation='relu',\n    kernel_initializer='random_normal',\n    bias_initializer='zeros'\n))\nmodel_keras.add(Dense(\n    1,\n    activation='sigmoid',\n    kernel_initializer='random_normal',\n    bias_initializer='zeros'\n))\nmodel_keras.compile(\n    optimizer=Adam(lr=np.exp(sigopt.get_parameter('log_learning_rate', np.log(0.01)))),\n    loss=f1_loss,\n    metrics=[f1]\n)\nmodel_keras.fit(\n    scaled_trainX,\n    trainY,\n    batch_size=sigopt.get_parameter('batch_size', default=4096),\n    epochs=sigopt.get_parameter('epochs', default=6),\n    callbacks=[CheckpointCB()],\n    validation_data=(scaled_testX, testY),\n)\n\n#Collect model metrics\nprobability = model_keras.predict(scaled_testX).flatten()\nprediction = np.where(probability > 0.5, np.ones_like(probability, dtype=bool), np.zeros_like(probability, dtype=bool))\n\nlog_all_metrics(prediction, probability, testY, testX)","execution_count":26,"outputs":[{"output_type":"stream","text":"Run started, view it on the SigOpt dashboard at https://app.sigopt.com/run/25005\nEpoch 1/6\n55/55 [==============================] - 1s 25ms/step - loss: -0.0737 - f1: 0.0605 - val_loss: -0.6215 - val_f1: 0.4328\nEpoch 2/6\n55/55 [==============================] - 1s 20ms/step - loss: -0.5320 - f1: 0.3645 - val_loss: -0.7405 - val_f1: 0.4849\nEpoch 3/6\n55/55 [==============================] - 1s 18ms/step - loss: -0.6247 - f1: 0.4308 - val_loss: -0.6985 - val_f1: 0.4534\nEpoch 4/6\n55/55 [==============================] - 1s 19ms/step - loss: -0.6152 - f1: 0.4133 - val_loss: -0.7430 - val_f1: 0.4777\nEpoch 5/6\n55/55 [==============================] - 1s 20ms/step - loss: -0.6453 - f1: 0.4325 - val_loss: -0.7988 - val_f1: 0.4964\nEpoch 6/6\n55/55 [==============================] - 1s 19ms/step - loss: -0.6745 - f1: 0.4272 - val_loss: -0.7754 - val_f1: 0.4934\nRun finished, view it on the SigOpt dashboard at https://app.sigopt.com/run/25005\n","name":"stdout"}]},{"metadata":{"id":"rU6mxQsE1n5o"},"cell_type":"markdown","source":"## Setting our baseline\n\nIn any optimization problem, it is critical to define a baseline so any uplift in performance can be evaluated against that baseline. In our scenario the baseline is running our XGBoost classifier with all default parameters. Let's now look at three SigOpt methods we are using to build consistency in our experimentation approach\n\n- [sigopt.get_parameter](https://app.sigopt.com/docs/runs/reference#get_parameter) allows us to store our defult parameters for the baseline model on our dashboard.\n- [sigopt.log_model](https://app.sigopt.com/docs/runs/reference#log_model) stores a text value that you can use to filter your runs in the SigOpt web view. In our example, you might want to filter by Fraud_Analysis to compare models of the same use case in the web charts.\n- The most important information about a model is how it performed. With [sigopt.log_metric](https://app.sigopt.com/docs/runs/reference#log_metric) you can take advantage of SigOpt's analysis dashboard of custom charts and advanced sorting and filtering.\n\nðŸš¦ **TO DO - Run the following code cell to create your baseline model, fit it, collect your performance metrics of other metrics of interest**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"0Fes7LBJ1n5p","outputId":"8582bc7b-815b-49bd-9f01-b53de604e4de","trusted":true,"scrolled":false},"cell_type":"code","source":"%%run XGBoost\nsigopt.log_model('XGboost for Fraud Analysis')\nsigopt.log_dataset(df_path)\n\nmodel = XGBClassifier(random_state = random_state)\n\nfor key, value in model.get_params().items():\n    print(key)\n    print(value)\n    sigopt.get_parameter(name=key, default=value)\n\nmodelfit = model.fit(trainX,trainY)\nprediction = modelfit.predict(testX)\nprobabilities = modelfit.predict_proba(testX)[:, 1]\n\n\nlog_all_metrics(prediction, probabilities, testY, testX)\n\n","execution_count":36,"outputs":[{"output_type":"stream","text":"Run started, view it on the SigOpt dashboard at https://app.sigopt.com/run/25009\nobjective\nbinary:logistic\nbase_score\nNone\nbooster\nNone\ncolsample_bylevel\nNone\ncolsample_bynode\nNone\ncolsample_bytree\nNone\ngamma\nNone\ngpu_id\nNone\nimportance_type\ngain\ninteraction_constraints\nNone\nlearning_rate\nNone\nmax_delta_step\nNone\nmax_depth\nNone\nmin_child_weight\nNone\nmissing\nnan\nRun finished, view it on the SigOpt dashboard at https://app.sigopt.com/run/25009\n","name":"stdout"},{"output_type":"error","ename":"ApiException","evalue":"ApiException (400): NaN","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-7ee80aef3f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XGBoost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigopt.log_model('XGboost for Fraud Analysis')\\nsigopt.log_dataset(df_path)\\n\\nmodel = XGBClassifier(random_state = random_state)\\n\\nfor key, value in model.get_params().items():\\n    print(key)\\n    print(value)\\n    sigopt.get_parameter(name=key, default=value)\\n\\nmodelfit = model.fit(trainX,trainY)\\nprediction = modelfit.predict(testX)\\nprobabilities = modelfit.predict_proba(testX)[:, 1]\\n\\n\\nlog_all_metrics(prediction, probabilities, testY, testX)\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-127>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, line, cell)\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/magics.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcell_magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/magics.py\u001b[0m in \u001b[0;36mexec_cell\u001b[0;34m(self, name, cell, ns, project_id, suggestion)\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mstream_monitor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# pylint: disable=exec-used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;31m# pylint: enable=exec-used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mstream_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream_monitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stream_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/runs/proxy.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/runs/context.py\u001b[0m in \u001b[0;36mfunction_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mupdate_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mupdate_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/runs/context.py\u001b[0m in \u001b[0;36m_update_run\u001b[0;34m(self, body)\u001b[0m\n\u001b[1;32m    247\u001b[0m       ),\n\u001b[1;32m    248\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m       \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'X-Response-Content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'skip'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/interface.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, headers)\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, json, headers, user_agent)\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mConnectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_with_default_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/sigopt/requestor.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mApiException\u001b[0m: ApiException (400): NaN"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(random_state = random_state)\nmodel.get_params()","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"{'objective': 'binary:logistic',\n 'base_score': None,\n 'booster': None,\n 'colsample_bylevel': None,\n 'colsample_bynode': None,\n 'colsample_bytree': None,\n 'gamma': None,\n 'gpu_id': None,\n 'importance_type': 'gain',\n 'interaction_constraints': None,\n 'learning_rate': None,\n 'max_delta_step': None,\n 'max_depth': None,\n 'min_child_weight': None,\n 'missing': nan,\n 'monotone_constraints': None,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'num_parallel_tree': None,\n 'random_state': 3,\n 'reg_alpha': None,\n 'reg_lambda': None,\n 'scale_pos_weight': None,\n 'subsample': None,\n 'tree_method': None,\n 'validate_parameters': None,\n 'verbosity': None}"},"metadata":{}}]},{"metadata":{"id":"htEMEDW21n5v"},"cell_type":"markdown","source":"ðŸš¦ **TO DO - Click the Run hyperlink above. You will be redirected to the the corresponding Run page. Now let's explore the UI and look at the data we collected during this Run**\n\n> Our AUPRC baseline is 0.96077. It is also worth noting that our baseline model only missed on 5 predictions, all False Negative (i.e. fraudulent activities that were predicted as non fraudulent) out of a total 55,585 predictions.\n\n___"},{"metadata":{"id":"AHgNhFT61n5x"},"cell_type":"markdown","source":"# Hyperparameter Optimization\n\nThe previous section illustrated how you can log and track a single run of your model by leveraging SigOpt training runs. We now want to leverage SigOpt optimization engine, and let the engine suggest sets of parameters for the purpose of tuning that same model. Similarly we'll now go over some SigOpt terminology.\n\n<img src=\"https://sigopt.com/wp-content/uploads/2019/05/SigOpt-interaction-model-1.png\" alt=\"Black Box Overview\"  width=\"700\"/>"},{"metadata":{"id":"O8NZEBX11n5y"},"cell_type":"markdown","source":"## Define your Parameter Space\n\nToday, we will explore the following parameter space\n- **min_child_weight**, used to control over-fitting, this parameter is the sample size under which the model can not split a node.  Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n- **max_depth**, this is the maximum depth of a tree.  This parameter controls over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n- **n_estimators**, this is the number of trees to fit.  Usually the higher the number of trees the better to learn the data. However, adding a lot of trees can slow down the training process and intoduce overfitting patterns.\n- **learning_rate** controls the weighting of new trees added to the model.  Lowering this value will prevent overfitting, but require the model to add a larger number of tree"},{"metadata":{"id":"WQ_ESwJq1n5z"},"cell_type":"markdown","source":"## Configure your Experiment\n\nThe experiment definition will include the name, project, which of your parameters to optimize, metrics and other options that you would like to run your experiment with. The observation budget is the number of runs you would like created in the optimization. We recommend using 20 for testing. When you're ready, visit the [observation budget page](https://app.sigopt.com/docs/overview/observation_budget) to learn our rule of thumb for the appropriate observation budget.\n\nYou can format the experiment definition in Python, YAML, or JSON. In this example, we're using YAML. See our documentation [here](https://app.sigopt.com/docs/runs/optimize#formatting) for Python and JSON examples and examples on how to create experiments using R, Matlab or Java.\n\nðŸš¦ **TO DO - Run the following code cell to create your experiment**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"1bl6qF0O1n5z","outputId":"23b3106e-3f0e-4470-d941-54fdb590f042","trusted":true},"cell_type":"code","source":"%%experiment\n'''\nname: Fraud_Analysis\nparameters:\n  - name: min_child_weight\n    bounds:\n      min: 1\n      max: 15\n    type: int\n  - name: max_depth\n    bounds:\n      min: 2\n      max: 15\n    type: int\n  - name: n_estimators\n    bounds:\n      min: 20\n      max: 400\n    type: int\n  - name: learning_rate\n    bounds:\n      min: 0.001\n      max: 1\n    transformation: log\n    type: double\nmetrics:\n  - name: AUPRC\n    objective: maximize\nobservation_budget: 20\n'''","execution_count":null,"outputs":[]},{"metadata":{"id":"ZDDeXfP31n52"},"cell_type":"markdown","source":"Once your experiment is created, you'll have a link to your experiment\n\nðŸš¦ **TO DO - Click the link above to confirm your experiment was properly created.**"},{"metadata":{"id":"TPWjipbs1n53"},"cell_type":"markdown","source":"## Instrument your model and run your Experiment\n\nWith SigOpt, it's very easy to instrument your  model and run an optimization loop. The [sigopt.get_parameter](https://app.sigopt.com/docs/runs/reference#get_parameter) method also allows us to access the parameter suggested throughout the optimization process. In our example, the parameters that we will be optimizing are **min_child_weight**, **max_depth**, **n_estimators** and **learning_rate**. **It is important to notice that SigOpt does not require you to optimize all of your parameters, meaning that you are able to keep the defult parameters that you don't want to optimize.** When running the optimization this method will seamlessly return a value generated from a SigOpt Experiment's Suggestion.\n\nðŸš¦ **TO DO - Run the following code cell to create the function that will generate a new model everytime SigOpt has a new set of hyperparameters to evaluate**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":697},"id":"guYMBJWZ1n54","outputId":"da613bb0-4eff-4b18-d3c7-c964d0233862","trusted":true},"cell_type":"code","source":"%%optimize\nsigopt.log_model('XGboost for Fraud Analysis')\nsigopt.log_dataset(df_path)\n\nfor key, value in zip(model.get_params().keys(), model.get_params().values()):\n    sigopt.get_parameter(name=key, default=value)\n\nmin_child_weight = sigopt.get_parameter('min_child_weight')\nmax_depth = sigopt.get_parameter('max_depth')\nn_estimators = sigopt.get_parameter('n_estimators')\nlearning_rate = sigopt.get_parameter('learning_rate')\n\n\nmodel = XGBClassifier(min_child_weight=min_child_weight,\n                      max_depth=max_depth,\n                      n_estimators=n_estimators,\n                      learning_rate=learning_rate,\n                      random_state = random_state)\n\nmodelfit = model.fit(trainX,trainY)\nprediction = modelfit.predict(testX)\nF1score = f1_score(testY,prediction)\nprobabilities = modelfit.predict_proba(testX)\nAUPRC = average_precision_score(testY, probabilities)\ntn, fp, fn, tp = confusion_matrix(testY,prediction).ravel()\n\nsigopt.log_metric('AUPRC', average_precision_score(testY, probabilities))\nsigopt.log_metric('F1score', F1score)\nsigopt.log_metric('False Positive', fp)\nsigopt.log_metric('False Negative', fn)\nsigopt.log_metric('True Positive', tp)\nsigopt.log_metric('True Negative', tn)\nsigopt.log_metric('Mean $ Error Fraudulent', error_fraud(prediction, testY, testX['amount']))\nsigopt.log_metric('Mean $ Error Valid', error_valid(prediction, testY, testX['amount']))","execution_count":null,"outputs":[]},{"metadata":{"id":"t2_idF5O1n56"},"cell_type":"markdown","source":"The [Optimization Loop](https://app.sigopt.com/docs/overview/optimization) is the backbone of using SigOpt.  In the code cell above, you run through the following three simple steps, in a loop\n- Receive a set of parameters suggestion from SigOpt\n- Evaluate your model objective metric\n- Report your model objective metric to SigOpt\n\n<img src=\"https://static.sigopt.com/b/7db309215269c8e1d7f88041f283b36b0e0f3884/static/img/optimization-loop.svg\" alt=\"Optimization Loop\"  width=\"250\"/>\n\nðŸš¦ **TO DO - Click the Run hyperlink above. You will be redirected to the the corresponding Run page. Now let's explore the UI and look at how an Experiment comprised of multiple runs differ from a single run like the baseline training run we created earlier.**\n\n"},{"metadata":{"id":"JaNNjJYh1n58"},"cell_type":"markdown","source":"## Multimetric Experimentation\n\nMost problems of practical relevance involve two or more competing objectives.  Even in a case like a fraud detection classifier where a clear measure of success is effectively blocking fraudulent transactions while allowing legitimate ones, the classifier inference time should be part of your model evaluation.  So far we've graded the accuracy of the model without worrying about inference time, or how fast we can predict whether a transaction is faudulent or not.  In real life, a model that returns a 99.99% accuracy is useless if it has to churn data for 20 seconds to provide an answer.  SigOpt support [multimetric problems](https://app.sigopt.com/docs/overview/multimetric) where 2 competing metrics can be optimized at the same time, and an additional 50 metrics can be stored.\n\nðŸš¦ **TO DO - Run the next three code cells. The first cell is an update to our experiment definition to include a second objective metric. The scond cell run the optimization loop**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"BssYLK721n59","outputId":"95e400e3-5121-4656-ca70-ca41e266c517","trusted":true},"cell_type":"code","source":"%%experiment\n'''\nname: Fraud_Analysis_Multimetric\nparameters:\n  - name: min_child_weight\n    bounds:\n      min: 1\n      max: 15\n    type: int\n  - name: max_depth\n    bounds:\n      min: 2\n      max: 15\n    type: int\n  - name: n_estimators\n    bounds:\n      min: 20\n      max: 400\n    type: int\n  - name: learning_rate\n    bounds:\n      min: 0.001\n      max: 1\n    type: double\n    transformation: log\nmetrics:\n  - name: AUPRC\n    objective: maximize\n  - name: Inference Time\n    objective: minimize    \nobservation_budget: 40\n'''","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Ky0jhDm31n5_","outputId":"fe5d0655-37b1-458f-dadc-c2f38d14876b","scrolled":true,"trusted":true},"cell_type":"code","source":"%%optimize\nsigopt.log_model('XGboost for Fraud Analysis using multimetric')\nsigopt.log_dataset(df_path)\n\nfor key, value in zip(model.get_params().keys(), model.get_params().values()):\n    sigopt.get_parameter(name=key, default=value)\n\nmin_child_weight = sigopt.get_parameter('min_child_weight')\nmax_depth = sigopt.get_parameter('max_depth')\nn_estimators = sigopt.get_parameter('n_estimators')\nlearning_rate = sigopt.get_parameter('learning_rate')\n\n\nmodel = XGBClassifier(min_child_weight=min_child_weight,\n                      max_depth=max_depth,\n                      n_estimators=n_estimators,\n                      learning_rate=learning_rate,\n                      random_state = random_state)\n\nmodelfit = model.fit(trainX,trainY)\nstart = time.time()\nprediction = modelfit.predict(testX)\ninferenceTime = time.time() - start\nF1score = f1_score(testY,prediction)\nprobabilities = modelfit.predict_proba(testX)\nAUPRC = average_precision_score(testY, probabilities[:, 1])\ntn, fp, fn, tp = confusion_matrix(testY,prediction).ravel()\n\nsigopt.log_metric('AUPRC', average_precision_score(testY, probabilities[:, 1]))\nsigopt.log_metric('Inference Time', inferenceTime)\nsigopt.log_metric('F1score', F1score)\nsigopt.log_metric('False Positive', fp)\nsigopt.log_metric('False Negative', fn)\nsigopt.log_metric('True Positive', tp)\nsigopt.log_metric('True Negative', tn)\nsigopt.log_metric('Mean $ Error Fraudulent', error_fraud(prediction, testY, testX['amount']))\nsigopt.log_metric('Mean $ Error Valid', error_valid(prediction, testY, testX['amount']))","execution_count":null,"outputs":[]},{"metadata":{"id":"dd9gcO0E1n6C"},"cell_type":"markdown","source":"ðŸš¦ **TO DO - Click the link above to open the analysis page. We'll first go over a little bit of theory around multimetric optimization, and the shape of a multimetric solution. Then dive into the analysis once everyone collect enough data to start seeing a pareto frontier**\n\n___"},{"metadata":{},"cell_type":"markdown","source":"# Learn more at your own time\n## EfficientBERT\n\nðŸš¦ **TO DO [At your own time] - Learn about optimization of efficient BERT by going through the [dashboard](https://app.sigopt.com/guest?guest_token=RDSLBTPPKENPFFAAWDXWGKRUGAJZOPTZZYCRVKCFOZWZZTYL) and watch this [presentation](https://www.youtube.com/watch?v=ZnBYV2h_6RA) by Machine Learning Engineer at SigOpt Meghana Ravikumar**\n\n> With the publication of BERT, transfer learning was suddenly accessible for NLP, unlocking a plethora of model zoos and boosting performances for domain specific problems.  Although BERT has accelerated many modeling efforts, its size is limiting. In this talk, we will explore how to reduce the size of BERT while retaining its capacity in the context of English Question Answering tasks. We'll show how scalable hyperparameter optimization can help you tackle difficult modeling problems, draw insights, and make informed decisions.\n\n> Our approach encompasses fine-tuning, distillation, architecture search, and hyperparameter optimization at scale. First, we fine-tune BERT on SQUAD 2.0 (our teacher model) and use distillation to compress fine-tuned BERT to a smaller model (our student model). Then, combining SigOpt and Ray, we use multimetric Bayesian optimization at scale to find the optimal architecture for the student model. Finally, we explore the trade-offs of our hyperparameter decisions to draw insights for our student model's architecture. \n\n___\n\n## Advanced features\n\nðŸš¦ **TO DO [At your own time] - [At your own time] Learn about SigOpt's [advanced features](https://app.sigopt.com/docs/overview/multimetric) for optimization**\n\n> The SigOp optimization engine goes beyond traditional hyperparameter tuning packages and methods with numerous advanced features that empower modelers to accelerate model development and solve new optimization problems.\n\n___\n\n\n## Documentation\n\nðŸš¦ **TO DO [At your own time] - [At your own time] Learn about SigOpt by looking through the [documentation](https://app.sigopt.com/docs)**\n\n___"}],"metadata":{"colab":{"name":"[O'Reilly] Intro_to_HPO_F9.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}